import logging
import openai
from openai import OpenAI
from aiogram import Bot  # –î–ª—è —Ä–∞–±–æ—Ç—ã —Å –±–æ—Ç–æ–º
from aiogram.types.input_file import InputFile
from googletranslatepy import Translator  # –ë–∏–±–ª–∏–æ—Ç–µ–∫–∞ –¥–ª—è –ø–µ—Ä–µ–≤–æ–¥–∞ —Ç–µ–∫—Å—Ç–∞
import speech_recognition as sr  # –ë–∏–±–ª–∏–æ—Ç–µ–∫–∞ –¥–ª—è —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è —Ä–µ—á–∏
from pydub import AudioSegment  # –ë–∏–±–ª–∏–æ—Ç–µ–∫–∞ –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å –∞—É–¥–∏–æ
import tempfile
import os
from config import OPENAPI_TOKEN, midjourney_webhook_url, MJ_API_KEY, TNL_API_KEY, TOKEN, NOTIFY_URL, TNL_API_KEY1, \
    ADMINS_CODER, PROJECT_MANAGER  # –ò–º–ø–æ—Ä—Ç –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–π –∏ —Ç–æ–∫–µ–Ω–æ–≤
from utils import db  # –†–∞–±–æ—Ç–∞ —Å –±–∞–∑–æ–π –¥–∞–Ω–Ω—ã—Ö
from utils.mj_apis import GoAPI, ApiFrame, MidJourneyAPI


logger = logging.getLogger(__name__)

logging.basicConfig(
    level=logging.INFO,
    format='%(filename)s:%(lineno)d #%(levelname)-8s '
           '[%(asctime)s] - %(name)s - %(message)s')


# –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º API-–∫–ª—é—á –¥–ª—è OpenAI
client = OpenAI(api_key=OPENAPI_TOKEN)

# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è MidJourneyAPI
mj_api = MidJourneyAPI(primary_api="goapi")  # –ù–∞—á–Ω–µ–º —Å GoAPI

# –§—É–Ω–∫—Ü–∏—è –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è MidJourney —Ç–æ–∫–µ–Ω–∞ –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç –∏–Ω–¥–µ–∫—Å–∞
def get_mj_token(index):

    if index == 0:
        return TNL_API_KEY
    elif index == 1:
        return TNL_API_KEY1


# –î–æ–±–∞–≤–ª–µ–Ω–∏–µ –¥–µ–π—Å—Ç–≤–∏—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –≤ –±–∞–∑—É –¥–∞–Ω–Ω—ã—Ö (–Ω–∞–ø—Ä–∏–º–µ—Ä, —Å–æ–∑–¥–∞–Ω–∏–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –∏–ª–∏ –∑–∞–ø—Ä–æ—Å –≤ AI)
async def add_mj_action(user_id, action_type):

    action_id = await db.add_action(user_id, action_type)  # –°–æ—Ö—Ä–∞–Ω—è–µ–º –¥–µ–π—Å—Ç–≤–∏–µ –≤ –±–∞–∑–µ
    try:
        requests.post(NOTIFY_URL + f"/action/{action_id}")  # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º —É–≤–µ–¥–æ–º–ª–µ–Ω–∏–µ –æ –Ω–æ–≤–æ–º –¥–µ–π—Å—Ç–≤–∏–∏
    except:
        pass
    return action_id

my_bot = Bot(TOKEN)
# –§—É–Ω–∫—Ü–∏—è –¥–ª—è –æ—Ç–ø—Ä–∞–≤–∫–∏ —Å–æ–æ–±—â–µ–Ω–∏—è –æ–± –æ—à–∏–±–∫–µ –∞–¥–º–∏–Ω—É –±–æ—Ç–∞
async def send_error(text):
    await my_bot.send_message(ADMINS_CODER, text)


# –§—É–Ω–∫—Ü–∏—è –¥–ª—è –ø–µ—Ä–µ–≤–æ–¥–∞ —Ç–µ–∫—Å—Ç–∞ –Ω–∞ –∞–Ω–≥–ª–∏–π—Å–∫–∏–π —è–∑—ã–∫
async def get_translate(text):
    # –ó–∞–º–µ–Ω—è–µ–º –¥–ª–∏–Ω–Ω–æ–µ —Ç–∏—Ä–µ –Ω–∞ –¥–≤–∞ –¥–µ—Ñ–∏—Å–∞
    text = text.replace("‚Äî", "--")

    # –í—ã–¥–µ–ª—è–µ–º –ø–∞—Ä–∞–º–µ—Ç—Ä—ã
    special_tags = re.findall(r'--\w+(?: [\w:]+)?', text)
    clean_text = re.sub(r'--\w+(?: [\w:]+)?', '', text).strip()

    # –ü–µ—Ä–µ–≤–æ–¥–∏–º
    translator = Translator(target="en")
    translated = translator.translate(clean_text)

    # –£–±–∏—Ä–∞–µ–º –ø—Ä–æ–±–µ–ª –ø–µ—Ä–µ–¥ –¥–µ—Ñ–∏—Å–∞–º–∏
    translated = re.sub(r'\s+-(\w)', r'-\1', translated)

    # –°–∫–ª–µ–∏–≤–∞–µ–º –≤—Å—ë
    result = f"{translated.strip()} {' '.join(special_tags)}"
    return result



import base64
import requests
import re


# –§—É–Ω–∫—Ü–∏—è –¥–ª—è –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –≤ base64
def image_url_to_base64(url):
    response = requests.get(url)
    if response.status_code == 200:
        image_base64 = base64.b64encode(response.content).decode('utf-8')
        return f"data:image/jpeg;base64,{image_base64}"  # –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ –ø—Ä–∞–≤–∏–ª—å–Ω—ã–π MIME-—Ç–∏–ø (jpeg/png)
    return None


# –§—É–Ω–∫—Ü–∏—è –¥–ª—è –æ—Ç–ø—Ä–∞–≤–∫–∏ –∑–∞–ø—Ä–æ—Å–∞ –≤ ChatGPT
async def get_gpt(messages, model):
    status = True
    tokens = 0
    content = ""

    try:
        model_map = {
            '4o-mini': 'gpt-4o-mini',
            '4_1': 'gpt-4.1',
            'o1': 'o1',
            'o3-mini': 'o3-mini'
        }

        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –∏ –æ–±—Ä–∞–±–æ—Ç–∫–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –≤ —Å–æ–æ–±—â–µ–Ω–∏–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
        for message in messages:
            if message["role"] == "user":
                if isinstance(message["content"], list):  # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —è–≤–ª—è–µ—Ç—Å—è –ª–∏ content —Å–ø–∏—Å–∫–æ–º
                    logger.info('message["content"] is list')
                    # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —Å–ø–∏—Å–æ–∫ –∫–æ–Ω—Ç–µ–Ω—Ç–∞
                    image_urls = [
                        item["image_url"]["url"]
                        for item in message["content"]
                        if item["type"] == "image_url"
                    ]
                    text_content = " ".join(
                        item["text"]
                        for item in message["content"]
                        if item["type"] == "text"
                    ).strip()
                else:
                    logger.info('message["content"] is string')
                    # –ò—â–µ–º —Å—Å—ã–ª–∫–∏ –Ω–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –≤ —Å—Ç—Ä–æ–∫–µ
                    image_urls = re.findall(r'(https?://\S+\.(?:jpg|jpeg|png|gif))', message["content"])
                    text_content = re.sub(r'(https?://\S+\.(?:jpg|jpeg|png|gif))', '', message["content"]).strip()

                # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º —Å–æ–æ–±—â–µ–Ω–∏–µ –≤ —Ñ–æ—Ä–º–∞—Ç —Å type: image_url
                new_content = []

                # –î–æ–±–∞–≤–ª—è–µ–º —Ç–µ–∫—Å—Ç (–µ—Å–ª–∏ –µ—Å—Ç—å)
                if text_content:
                    new_content.append({"type": "text", "text": text_content})

                # –î–æ–±–∞–≤–ª—è–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –≤ —Ñ–æ—Ä–º–∞—Ç–µ base64
                for url in image_urls:
                    base64_image = image_url_to_base64(url)
                    if base64_image:
                        new_content.append({
                            "type": "image_url",
                            "image_url": {"url": base64_image}
                        })

                # –ó–∞–º–µ–Ω—è–µ–º –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ –Ω–∞ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–Ω–æ–µ
                message["content"] = new_content

        if model in {'o1'}:
            if messages and messages[0]["role"] == "system":
                messages[0] = {"role": "user", "content": "You are a helpful assistant."}

        logger.info(f'MESSAGES: {messages}')

        response = client.chat.completions.create(
            model=f"{model_map[model]}",
            messages=messages[-10:]  # –ü–æ—Å–ª–µ–¥–Ω–∏–µ 10 —Å–æ–æ–±—â–µ–Ω–∏–π
        )

        content = response.choices[0].message.content  # –ü–æ–ª—É—á–∞–µ–º –æ—Ç–≤–µ—Ç
        tokens = response.usage.total_tokens  # –ü–æ–ª—É—á–∞–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–Ω—ã—Ö —Ç–æ–∫–µ–Ω–æ–≤


    except openai.OpenAIError as e:
        status = False
        error_message = str(e)  # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –∏—Å–∫–ª—é—á–µ–Ω–∏–µ –≤ —Å—Ç—Ä–æ–∫—É
        logging.error(f'ChatGPT Error {error_message}')
        if "insufficient_quota" in error_message:
            await my_bot.send_message(PROJECT_MANAGER, "‚ö†Ô∏è –í–Ω–∏–º–∞–Ω–∏–µ! –ë–∞–ª–∞–Ω—Å ChatGPT –∏—Å—á–µ—Ä–ø–∞–Ω. –ù–µ–æ–±—Ö–æ–¥–∏–º–æ –µ–≥–æ –ø–æ–ø–æ–ª–Ω–∏—Ç—å! üí≥")
        else:
            content = "–ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Ç–µ–∫—Å—Ç–∞ –≤—Ä–µ–º–µ–Ω–Ω–æ –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∞, –ø–æ–≤—Ç–æ—Ä–∏—Ç–µ –∑–∞–ø—Ä–æ—Å –ø–æ–∑–¥–Ω–µ–µ."

    return {"status": status, "content": content, "tokens": tokens}  # –í–æ–∑–≤—Ä–∞—â–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç


# –§—É–Ω–∫—Ü–∏—è –¥–ª—è –æ—Ç–ø—Ä–∞–≤–∫–∏ –∑–∞–ø—Ä–æ—Å–∞ –≤ MidJourney
async def get_mdjrny(prompt, user_id):

    translated_prompt = await get_translate(prompt)  # –ü–µ—Ä–µ–≤–æ–¥–∏–º –∑–∞–ø—Ä–æ—Å –Ω–∞ –∞–Ω–≥–ª–∏–π—Å–∫–∏–π
    request_id = await db.add_action(user_id, "image", "imagine")  # –°–æ—Ö—Ä–∞–Ω—è–µ–º –¥–µ–π—Å—Ç–≤–∏–µ –≤ –±–∞–∑–µ –¥–∞–Ω–Ω—ã—Ö
    response = await mj_api.imagine(translated_prompt, request_id)  # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –∑–∞–ø—Ä–æ—Å –≤ Midjourney

    return response


# –§—É–Ω–∫—Ü–∏—è –¥–ª—è –≤—ã–±–æ—Ä–∞ –∏ —É–ª—É—á—à–µ–Ω–∏—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –≤ MidJourney
async def get_choose_mdjrny(task_id, image_id, user_id):

    action_id = await db.add_action(user_id, "image", "upscale")  # –°–æ—Ö—Ä–∞–Ω—è–µ–º –¥–µ–π—Å—Ç–≤–∏–µ –≤ –±–∞–∑–µ –¥–∞–Ω–Ω—ã—Ö

    response = await mj_api.upscale(task_id, image_id, action_id)  # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –∑–∞–ø—Ä–æ—Å –Ω–∞ —É–ª—É—á—à–µ–Ω–∏–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
    return response


# –§—É–Ω–∫—Ü–∏—è –¥–ª—è –Ω–∞–∂–∞—Ç–∏—è –∫–Ω–æ–ø–æ–∫ MidJourney (–≤–∞—Ä–∏–∞—Ü–∏–∏ –∏–ª–∏ —É–ª—É—á—à–µ–Ω–∏—è)
async def press_mj_button(button, buttonMessageId, user_id, api_key_number):
    
    action_id = await db.add_action(user_id, "image", "imagine")  # –°–æ—Ö—Ä–∞–Ω—è–µ–º –¥–µ–π—Å—Ç–≤–∏–µ –≤ –±–∞–∑–µ –¥–∞–Ω–Ω—ã—Ö
    status = True
    api_key = get_mj_token(api_key_number)  # –ü–æ–ª—É—á–∞–µ–º —Ç–æ–∫–µ–Ω
    try:
        payload = {
            "button": button,
            "buttonMessageId": buttonMessageId,
            "ref": str(action_id),
            "webhookOverride": midjourney_webhook_url + "/button"
        }
        headers = {
            'Content-Type': 'application/json',
            'Authorization': f'Bearer {api_key}'
        }
        res = requests.post("https://api.justimagineapi.org/v1" + "/button", json=payload, headers=headers)  # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –∑–∞–ø—Ä–æ—Å
        res = res.json()
    except requests.exceptions.JSONDecodeError:
        status = False  # –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ JSON
    return status


"""–†–∞–±–æ—Ç–∞ —Å –≥–æ–ª–æ—Å–æ–≤—ã–º–∏ —Å–æ–æ–±—â–µ–Ω–∏—è–º–∏"""
# –§—É–Ω–∫—Ü–∏—è –¥–ª—è –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏—è –≥–æ–ª–æ—Å–æ–≤–æ–≥–æ —Å–æ–æ–±—â–µ–Ω–∏—è –≤ —Ç–µ–∫—Å—Ç
def voice_to_text(file_path):
    recognizer = sr.Recognizer()
    audio = AudioSegment.from_file(file_path)
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∞—É–¥–∏–æ –∫–∞–∫ –≤—Ä–µ–º–µ–Ω–Ω—ã–π wav-—Ñ–∞–π–ª
    with tempfile.NamedTemporaryFile(delete=False, suffix=".wav") as temp_wav_file:
        audio.export(temp_wav_file.name, format="wav")
        temp_wav_file_path = temp_wav_file.name

    with sr.AudioFile(temp_wav_file_path) as source:
        audio_data = recognizer.record(source)
        
    os.remove(temp_wav_file_path)  # –£–¥–∞–ª—è–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–π —Ñ–∞–π–ª
    
    try:
        text = recognizer.recognize_google(audio_data, language="ru-RU")
        return text
    except sr.UnknownValueError:
        return "–ù–µ —É–¥–∞–ª–æ—Å—å —Ä–∞—Å–ø–æ–∑–Ω–∞—Ç—å —Ä–µ—á—å"
    except sr.RequestError:
        return "–û—à–∏–±–∫–∞ –∑–∞–ø—Ä–æ—Å–∞ –∫ —Å–µ—Ä–≤–∏—Å—É —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è"

def text_to_speech(text, model="tts-1", voice="onyx"):

    # –°–æ–∑–¥–∞–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–π —Ñ–∞–π–ª –¥–ª—è –∞—É–¥–∏–æ
    with tempfile.NamedTemporaryFile(delete=False, suffix=".mp3") as temp_audio_file:
        temp_audio_path = temp_audio_file.name

    # –ó–∞–ø—Ä–æ—Å –∫ OpenAI –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è –∞—É–¥–∏–æ
    response = client.audio.speech.create(
        model=model,
        voice=voice,
        input=text
    )

    # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç –≤ —Ñ–∞–π–ª
    response.stream_to_file(temp_audio_path)
    audio_file = InputFile(temp_audio_path)

    return audio_file


