from io import BytesIO
from aiogram.types import InlineKeyboardMarkup, InlineKeyboardButton
from aiogram import types
from aiogram.dispatcher import FSMContext
from aiogram.dispatcher.filters.state import State, StatesGroup
from openai import OpenAI
import base64
import tempfile
import os
import json
from config import OPENAPI_TOKEN
from create_bot import dp, bot
from handlers.users import not_enough_balance
from keyboards.user import image_openai_menu, image_settings_menu, size_menu, quality_menu, background_menu, \
    cancel_keyboard

from utils import db
from utils.ai import get_translate
from typing import Literal
import logging

from utils.db import update_image_openai_settings

PERSISTENT_TEMP_DIR = "persistent_temp"
os.makedirs(PERSISTENT_TEMP_DIR, exist_ok=True)

logger = logging.getLogger(__name__)

logging.basicConfig(
    level=logging.INFO,
    format='%(filename)s:%(lineno)d #%(levelname)-8s '
           '[%(asctime)s] - %(name)s - %(message)s')


# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∫–ª–∏–µ–Ω—Ç–∞ OpenAI
# client = OpenAI(api_key=OPENAPI_TOKEN)
from tests.mock_openai import MockOpenAIClient
client = MockOpenAIClient(image_path="photo_test/generated.png")

# FSM –¥–ª—è —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è —Å–æ—Å—Ç–æ—è–Ω–∏–µ–º –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π
class ImageGenerationStates(StatesGroup):
    WAITING_FOR_PROMPT = State()
    WAITING_FOR_IMAGES = State()
    WAITING_FOR_MASK = State()
    WAITING_FOR_PROMPT_MASK = State()
    WAITING_FOR_PROMPT_EDIT_IMAGE = State()
    WAITING_FOR_IMAGE_FIRST = State()

# –î–æ–ø—É—Å—Ç–∏–º—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è
ALLOWED_SIZES = {
    "auto",
    "1024x1024", "1536x1024", "1024x1536",
    "256x256", "512x512",
    "1792x1024", "1024x1792"
}

ALLOWED_QUALITY = {
    "standard", "hd", "low", "medium", "high", "auto"
}

ALLOWED_BACKGROUND = {
    "transparent", "opaque", "auto"
}

# –¢–∏–ø—ã –¥–ª—è —Å—Ç—Ä–æ–≥–æ–π —Ç–∏–ø–∏–∑–∞—Ü–∏–∏
SizeType = Literal[
    "auto",
    "1024x1024", "1536x1024", "1024x1536",
    "256x256", "512x512",
    "1792x1024", "1024x1792"
]
QualityType = Literal["standard", "hd", "low", "medium", "high", "auto"]
BackgroundType = Literal["transparent", "opaque", "auto"]


# –°–ª–æ–≤–∞—Ä—å —Å—Ç–æ–∏–º–æ—Å—Ç–∏ —Ç–æ–∫–µ–Ω–æ–≤ –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç —Ä–∞–∑–º–µ—Ä–∞ –∏ –∫–∞—á–µ—Å—Ç–≤–∞
def calculate_token_cost(size, quality):
    cost_map = {
        ("1024x1024", "low"): 272,
        ("1024x1024", "medium"): 1056,
        ("1024x1024", "high"): 4160,

        ("1536x1024", "low"): 400,
        ("1536x1024", "medium"): 1568,
        ("1536x1024", "high"): 6208,

        ("1024x1536", "low"): 408,
        ("1024x1536", "medium"): 1584,
        ("1024x1536", "high"): 6240,
    }
    return cost_map.get((size, quality), 1056)




# –ù–∞—á–∞–ª–æ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –ø–æ —Ç–µ–∫—Å—Ç—É
@dp.callback_query_handler(lambda c: c.data == "generate_image_prompt")
async def start_generate_image(callback_query: types.CallbackQuery, state: FSMContext):
    await callback_query.answer()
    user_id = callback_query.from_user.id

    if not await db.has_image_openai_balance(user_id):
        logger.info(f'–£ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è {user_id} –Ω–µ—Ç –≥–µ–Ω–µ—Ä–∞—Ü–∏–π –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –æ—Ç OpenAI, –ø–µ—Ä–µ–¥–∞–µ–º –º–µ–Ω—é —Å –ø–æ–∫—É–ø–∫–æ–π –≥–µ–Ω–µ—Ä–∞—Ü–∏–π')
        await not_enough_balance(callback_query.bot, user_id, "image_openai")
        return

    await callback_query.message.edit_text("""<b>‚úçÔ∏è –í–≤–µ–¥–∏—Ç–µ —Ç–µ–∫—Å—Ç–æ–≤–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è.</b>
<i>–ù–∞–ø—Ä–∏–º–µ—Ä:</i> <code>–£—é—Ç–Ω—ã–π –¥–æ–º–∏–∫ –Ω–∞ –∫—Ä–∞—é –ø—Ä–æ–ø–∞—Å—Ç–∏, –æ–∫—Ä—É–∂—ë–Ω–Ω—ã–π —Ü–≤–µ—Ç—É—â–∏–º–∏ —Å–∞–¥–∞–º–∏ –∏ –æ–∑—ë—Ä–∞–º–∏ —Å –æ—Ç—Ä–∞–∂–∞—é—â–∏–º—Å—è –Ω–µ–±–æ–º</code>

<u><a href="https://telegra.ph/Kak-polzovatsya-MidJourney-podrobnaya-instrukciya-10-16">–ü–æ–¥—Ä–æ–±–Ω–∞—è –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏—è.</a></u>""",
                         disable_web_page_preview=True, reply_markup=cancel_keyboard)

    await ImageGenerationStates.WAITING_FOR_PROMPT.set()


def parse_image_settings(settings_str: str) -> dict[str, str]:
    try:
        data = json.loads(settings_str)
    except json.JSONDecodeError:
        data = {}

    size = data.get("size", "1024x1024")
    if size not in ALLOWED_SIZES:
        size = "1024x1024"

    quality = data.get("quality", "medium")
    if quality not in ALLOWED_QUALITY:
        quality = "medium"

    background = data.get("background", "opaque")
    if background not in ALLOWED_BACKGROUND:
        background = "opaque"

    return {
        "size": size,
        "quality": quality,
        "background": background
    }


# –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –Ω–∞ –æ—Å–Ω–æ–≤–µ –ø—Ä–æ–º–ø—Ç–∞
@dp.message_handler(state=ImageGenerationStates.WAITING_FOR_PROMPT)
async def generate_image_from_prompt(message: types.Message, state: FSMContext):
    user_id = message.from_user.id
    prompt = message.text.strip()
    logger.info(f'–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è OpenAI, –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å {user_id}, prompt: {prompt} ')
    prompt = await get_translate(prompt)  # –ü–µ—Ä–µ–≤–æ–¥–∏–º –∑–∞–ø—Ä–æ—Å –Ω–∞ –∞–Ω–≥–ª–∏–π—Å–∫–∏–π

    if not prompt:
        await message.answer("‚ùå –û–ø–∏—Å–∞–Ω–∏–µ –Ω–µ –º–æ–∂–µ—Ç –±—ã—Ç—å –ø—É—Å—Ç—ã–º. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ —Å–Ω–æ–≤–∞.")
        return

    user = await db.get_user(user_id)

    settings = parse_image_settings(user["image_openai_settings"])
    size: SizeType = settings["size"]
    quality: QualityType = settings["quality"]
    background: BackgroundType = settings["background"]

    try:
        result = client.images.generate(
            model="gpt-image-1",
            prompt=prompt,
            size=size,
            quality=quality,
            background=background
        )

        image_base64 = result.data[0].b64_json
        image_bytes = base64.b64decode(image_base64)

        # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—é
        await bot.send_photo(chat_id=user_id, photo=types.InputFile(BytesIO(image_bytes), filename="generated.png"))

        # –£–º–µ–Ω—å—à–∞–µ–º –±–∞–ª–∞–Ω—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
        await db.decrease_image_openai_balance(user_id)

        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –¥–µ–π—Å—Ç–≤–∏–µ –≤ –±–∞–∑–µ –¥–∞–Ω–Ω—ã—Ö
        await db.add_action(user_id, "image_openai", "generate")
        # –õ–æ–≥–∏—Ä—É–µ–º –¥–µ–π—Å—Ç–≤–∏–µ
        logger.info(f"–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å {user_id} —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–ª –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ: {prompt[:50]}...")

    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –¥–ª—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è {user_id}: {e}", exc_info=True)
        await message.answer("–ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –ø—Ä–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –ø–æ–∑–∂–µ.")

    finally:
        await state.finish()


# –ù–∞—á–∞–ª–æ —Ä–µ–¥–∞–∫—Ç–∏—Ä–æ–≤–∞–Ω–∏—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
@dp.callback_query_handler(lambda c: c.data == "edit_image")
async def start_edit_image(callback_query: types.CallbackQuery, state: FSMContext):
    await callback_query.answer()
    user_id = callback_query.from_user.id

    if not await db.has_image_openai_balance(user_id):
        await not_enough_balance(callback_query.bot, user_id, "image_openai")
        return

    await callback_query.message.edit_text("""<b>üì∏ –ü—Ä–∏—à–ª–∏—Ç–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è, –∫–æ—Ç–æ—Ä—ã–µ —Ö–æ—Ç–∏—Ç–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –∫–∞–∫ –æ—Å–Ω–æ–≤—É –¥–ª—è —Ä–µ–¥–∞–∫—Ç–∏—Ä–æ–≤–∞–Ω–∏—è.</b>"
<i>–í—ã –º–æ–∂–µ—Ç–µ:
- –†–µ–¥–∞–∫—Ç–∏—Ä–æ–≤–∞—Ç—å —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
- –°–æ–∑–¥–∞–≤–∞–π—Ç–µ –Ω–æ–≤—ã–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è, –∏—Å–ø–æ–ª—å–∑—É—è –¥—Ä—É–≥–∏–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –≤ –∫–∞—á–µ—Å—Ç–≤–µ —Å–ø—Ä–∞–≤–æ—á–Ω—ã—Ö –º–∞—Ç–µ—Ä–∏–∞–ª–æ–≤.</i>

<u><a href="https://telegra.ph/Kak-polzovatsya-MidJourney-podrobnaya-instrukciya-10-16">–ü–æ–¥—Ä–æ–±–Ω–∞—è –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏—è.</a></u>""",
                                           disable_web_page_preview=True, reply_markup=cancel_keyboard)

    await ImageGenerationStates.WAITING_FOR_IMAGES.set()


# –û–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π
@dp.message_handler(content_types=['photo'], state=ImageGenerationStates.WAITING_FOR_IMAGES)
async def handle_images_upload(message: types.Message, state: FSMContext):
    user_id = message.from_user.id
    data = await state.get_data()
    images_paths = data.get("images_paths", [])

    if len(images_paths) >= 10:
        await message.answer("‚ö†Ô∏è –í—ã –Ω–µ –º–æ–∂–µ—Ç–µ –∑–∞–≥—Ä—É–∑–∏—Ç—å –±–æ–ª—å—à–µ 10 –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π.")
        return

    photo = message.photo[-1]
    file = await bot.get_file(photo.file_id)
    downloaded_file = await bot.download_file(file.file_path)

    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –≤ –ø–æ—Å—Ç–æ—è–Ω–Ω–æ–π –≤—Ä–µ–º–µ–Ω–Ω–æ–π –ø–∞–ø–∫–µ
    image_filename = f"{user_id}_{len(images_paths)}.png"
    image_path = os.path.join(PERSISTENT_TEMP_DIR, image_filename)

    with open(image_path, 'wb') as new_file:
        new_file.write(downloaded_file.getvalue())

    images_paths.append(image_path)
    await state.update_data(images_paths=images_paths)

    keyboard = InlineKeyboardMarkup().add(
        InlineKeyboardButton("‚úÖ –ó–∞–≤–µ—Ä—à–∏—Ç—å –∑–∞–≥—Ä—É–∑–∫—É", callback_data="finish_image_upload"),
        InlineKeyboardButton("‚ùå –û—Ç–º–µ–Ω–∞", callback_data="cancel_action"),
    )

    if len(images_paths) == 1:
        await message.answer("üñºÔ∏è –ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –∑–∞–≥—Ä—É–∂–µ–Ω–æ. –•–æ—Ç–∏—Ç–µ –¥–æ–±–∞–≤–∏—Ç—å –µ—â–µ?", reply_markup=keyboard)
    else:
        await message.answer(f"üñºÔ∏è –ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(images_paths)} –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π.", reply_markup=keyboard)


@dp.callback_query_handler(lambda c: c.data == "finish_image_upload", state=ImageGenerationStates.WAITING_FOR_IMAGES)
async def finish_image_upload(callback_query: types.CallbackQuery, state: FSMContext):
    await callback_query.answer()
    await callback_query.message.edit_text("""<b>‚úçÔ∏è–¢–µ–ø–µ—Ä—å –≤–≤–µ–¥–∏—Ç–µ —Ç–µ–∫—Å—Ç–æ–≤–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ, –∫–∞–∫ –≤—ã —Ö–æ—Ç–∏—Ç–µ –∏–∑–º–µ–Ω–∏—Ç—å —ç—Ç–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ.
–ï—Å–ª–∏ –Ω–µ—Å–∫–æ–ª—å–∫–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π, —Ç–æ –º–æ–∂–Ω–æ —Å–æ–∑–¥–∞—Ç—å –Ω–æ–≤–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –∏–∑ –Ω–∏—Ö.</b>

<i>–ù–∞–ø—Ä–∏–º–µ—Ä:</i> <code>–°–æ–∑–¥–∞–π –ø–æ–¥–∞—Ä–æ—á–Ω—É—é –∫–æ—Ä–∑–∏–Ω—É, —Å–æ–¥–µ—Ä–∂–∞—â—É—é –ø—Ä–µ–¥–º–µ—Ç—ã —Å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π</code>

<u><a href="https://telegra.ph/Kak-polzovatsya-MidJourney-podrobnaya-instrukciya-10-16">–ü–æ–¥—Ä–æ–±–Ω–∞—è –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏—è.</a></u>""",
                                           disable_web_page_preview=True, reply_markup=cancel_keyboard)
    await ImageGenerationStates.WAITING_FOR_PROMPT_EDIT_IMAGE.set()



@dp.message_handler(state=ImageGenerationStates.WAITING_FOR_PROMPT_EDIT_IMAGE)
async def handle_edit_prompt(message: types.Message, state: FSMContext):
    prompt = message.text.strip()
    user_id = message.from_user.id
    data = await state.get_data()
    images_paths = data.get('images_paths', [])
    mask_path = data.get('mask_path')

    if not images_paths:
        await message.answer("‚ùå –ù–µ –Ω–∞–π–¥–µ–Ω–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –¥–ª—è —Ä–µ–¥–∞–∫—Ç–∏—Ä–æ–≤–∞–Ω–∏—è.")
        return

    user = await db.get_user(user_id)
    settings = parse_image_settings(user["image_openai_settings"])
    size: SizeType = settings["size"]
    quality: QualityType = settings["quality"]
    background: BackgroundType = settings["background"]

    image_file = None
    image_files = []
    mask_file = None

    try:
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –≤—Å–µ—Ö —Ñ–∞–π–ª–æ–≤
        for path in images_paths:
            if not os.path.exists(path):
                raise FileNotFoundError(f"–§–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω: {path}")
        if mask_path and not os.path.exists(mask_path):
            raise FileNotFoundError(f"–ú–∞—Å–∫–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω–∞: {mask_path}")

        if mask_path:
            # –†–µ–¥–∞–∫—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ —Å –º–∞—Å–∫–æ–π: –∏—Å–ø–æ–ª—å–∑—É–µ–º —Ç–æ–ª—å–∫–æ –ø–µ—Ä–≤–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
            image_file = open(images_paths[0], "rb")
            mask_file = open(mask_path, "rb")

            result = client.images.edit(
                model="gpt-image-1",
                image=image_file,
                mask=mask_file,
                prompt=prompt,
                size=size,
                quality=quality,
                background=background
            )
        else:
            # –†–µ–¥–∞–∫—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ —Å –Ω–µ—Å–∫–æ–ª—å–∫–∏–º–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è–º–∏
            image_files = [open(p, "rb") for p in images_paths]

            result = client.images.edit(
                model="gpt-image-1",
                image=image_files,
                prompt=prompt,
                size=size,
                quality=quality,
                background=background
            )

        # –ü–æ–ª—É—á–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
        image_base64 = result.data[0].b64_json
        image_bytes = base64.b64decode(image_base64)

        # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—é
        await bot.send_photo(
            chat_id=user_id,
            photo=types.InputFile(BytesIO(image_bytes), filename="edited.png")
        )

        # –û–±–Ω–æ–≤–ª—è–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
        await db.decrease_image_openai_balance(user_id)
        await db.add_action(user_id, "image_openai", "edit")
        logger.info(f"–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å {user_id} –æ—Ç—Ä–µ–¥–∞–∫—Ç–∏—Ä–æ–≤–∞–ª –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ: {prompt[:50]}...")

    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Ä–µ–¥–∞–∫—Ç–∏—Ä–æ–≤–∞–Ω–∏–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –¥–ª—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è {user_id}: {e}", exc_info=True)
        await message.answer("‚ùå –ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –ø—Ä–∏ —Ä–µ–¥–∞–∫—Ç–∏—Ä–æ–≤–∞–Ω–∏–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –ø–æ–∑–∂–µ.")

    finally:
        await state.finish()

        # –ó–∞–∫—Ä—ã–≤–∞–µ–º –≤—Å–µ –æ—Ç–∫—Ä—ã—Ç—ã–µ —Ñ–∞–π–ª—ã
        if image_file:
            image_file.close()
        if mask_file:
            mask_file.close()
        for f in image_files:
            f.close()

        # –£–¥–∞–ª—è–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–µ —Ñ–∞–π–ª—ã
        for path in images_paths:
            if os.path.exists(path):
                os.remove(path)
        if mask_path and os.path.exists(mask_path):
            os.remove(mask_path)


# –û–±—Ä–∞–±–æ—Ç–∫–∞ –º–∞—Å–∫–∏ –¥–ª—è inpainting
@dp.callback_query_handler(lambda c: c.data == "use_mask_for_edit")
async def use_mask_for_edit(callback_query: types.CallbackQuery, state: FSMContext):
    await callback_query.answer()
    await callback_query.message.edit_text("""<b>–í—ã –º–æ–∂–µ—Ç–µ —Ä–µ–¥–∞–∫—Ç–∏—Ä–æ–≤–∞—Ç—å —á–∞—Å—Ç–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è, –∑–∞–≥—Ä—É–∑–∏–≤ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –∏ –º–∞—Å–∫—É, —É–∫–∞–∑—ã–≤–∞—é—â—É—é, –∫–∞–∫–∏–µ –æ–±–ª–∞—Å—Ç–∏ —Å–ª–µ–¥—É–µ—Ç –∑–∞–º–µ–Ω–∏—Ç—å.

üñºÔ∏è –°–Ω–∞—á–∞–ª–∞ –∑–∞–≥—Ä—É–∑–∏—Ç–µ –æ—Å–Ω–æ–≤–Ω–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ.</b>

<u><a href="https://telegra.ph/Kak-polzovatsya-MidJourney-podrobnaya-instrukciya-10-16">–ü–æ–¥—Ä–æ–±–Ω–∞—è –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏—è.</a></u>""",
                                           disable_web_page_preview=True, reply_markup=cancel_keyboard)
    await ImageGenerationStates.WAITING_FOR_IMAGE_FIRST.set()

#  –û–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –æ—Å–Ω–æ–≤–Ω–æ–≥–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
@dp.message_handler(content_types=['photo'], state=ImageGenerationStates.WAITING_FOR_IMAGE_FIRST)
async def handle_base_image_upload(message: types.Message, state: FSMContext):
    user_id = message.from_user.id
    photo = message.photo[-1]
    file = await bot.get_file(photo.file_id)
    downloaded_file = await bot.download_file(file.file_path)

    temp_dir = tempfile.TemporaryDirectory()
    image_path = os.path.join(temp_dir.name, f"{user_id}_base.png")

    with open(image_path, 'wb') as new_file:
        new_file.write(downloaded_file.getvalue())

    await state.update_data(base_image=image_path, temp_dir=temp_dir)
    await message.answer("üñºÔ∏è –¢–µ–ø–µ—Ä—å –∑–∞–≥—Ä—É–∑–∏—Ç–µ –º–∞—Å–∫—É. –ó–∞–∫—Ä–∞—à–µ–Ω–Ω—ã–µ –æ–±–ª–∞—Å—Ç–∏ –±—É–¥—É—Ç –∏–∑–º–µ–Ω–µ–Ω—ã.", reply_markup=cancel_keyboard)
    await ImageGenerationStates.WAITING_FOR_MASK.set()

# –û–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –º–∞—Å–∫–∏
@dp.message_handler(content_types=['photo'], state=ImageGenerationStates.WAITING_FOR_MASK)
async def handle_mask_upload(message: types.Message, state: FSMContext):
    data = await state.get_data()
    base_image_path = data.get("base_image")

    if not base_image_path:
        await message.answer("‚ùå –û—Å–Ω–æ–≤–Ω–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ —Å–Ω–æ–≤–∞.", reply_markup=cancel_keyboard)
        return

    user_id = message.from_user.id
    photo = message.photo[-1]
    file = await bot.get_file(photo.file_id)
    downloaded_file = await bot.download_file(file.file_path)

    mask_path = os.path.join(os.path.dirname(base_image_path), f"{user_id}_mask.png")

    with open(mask_path, 'wb') as new_file:
        new_file.write(downloaded_file.getvalue())

    await state.update_data(mask_path=mask_path)
    await message.answer("‚úçÔ∏è –¢–µ–ø–µ—Ä—å –æ—Ç–ø—Ä–∞–≤—å—Ç–µ –æ–ø–∏—Å–∞–Ω–∏–µ —Ç–æ–≥–æ, —á—Ç–æ –≤—ã —Ö–æ—Ç–∏—Ç–µ –∏–∑–º–µ–Ω–∏—Ç—å.", reply_markup=cancel_keyboard)
    await ImageGenerationStates.WAITING_FOR_PROMPT.set()



@dp.callback_query_handler(lambda c: c.data == "cancel_action", state="*")
async def cancel_action_handler(callback_query: types.CallbackQuery, state: FSMContext):
    await callback_query.answer()
    current_state = await state.get_state()
    if current_state:
        await state.finish()

    await callback_query.message.edit_text("–í—ã–±–µ—Ä–∏—Ç–µ –¥–µ–π—Å—Ç–≤–∏–µ:", reply_markup=image_openai_menu)

# –û–±—Ä–∞–±–æ—Ç—á–∏–∫ –≤—ã–∑–æ–≤–∞ –Ω–∞—Å—Ç—Ä–æ–µ–∫
@dp.callback_query_handler(lambda c: c.data == "image_settings")
async def image_settings_handler(callback_query: types.CallbackQuery):
    await callback_query.answer()
    user_id = callback_query.from_user.id
    user = await db.get_user(user_id)
    settings = parse_image_settings(user["image_openai_settings"])

    size = settings["size"]
    quality = settings["quality"]
    background = settings["background"]

    text = f"‚öôÔ∏è –¢–µ–∫—É—â–∏–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è:\n\n"
    text += f"üìê –†–∞–∑–º–µ—Ä: <b>{size}</b>\n"
    text += f"üñºÔ∏è –ö–∞—á–µ—Å—Ç–≤–æ: <b>{quality}</b>\n"
    text += f"üé® –§–æ–Ω: <b>{background}</b>\n\n"
    text += "–í—ã–±–µ—Ä–∏—Ç–µ, —á—Ç–æ –≤—ã —Ö–æ—Ç–∏—Ç–µ –∏–∑–º–µ–Ω–∏—Ç—å."

    await callback_query.message.edit_text(text, reply_markup=image_settings_menu, parse_mode="HTML")

# –û–±—Ä–∞–±–æ—Ç—á–∏–∫–∏ –ø–æ–¥–º–µ–Ω—é
@dp.callback_query_handler(lambda c: c.data.startswith("change_"))
async def show_settings_submenu(callback_query: types.CallbackQuery):
    await callback_query.answer()
    data_map = {
        "change_size": ("üìê –í—ã–±–µ—Ä–∏—Ç–µ —Ä–∞–∑–º–µ—Ä:", size_menu),
        "change_quality": ("üñºÔ∏è –í—ã–±–µ—Ä–∏—Ç–µ –∫–∞—á–µ—Å—Ç–≤–æ:", quality_menu),
        "change_background": ("üé® –í—ã–±–µ—Ä–∏—Ç–µ —Ñ–æ–Ω:", background_menu),
    }

    msg, menu = data_map.get(callback_query.data, ("–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–∞—è –Ω–∞—Å—Ç—Ä–æ–π–∫–∞", None))

    if menu:
        await callback_query.message.edit_text(msg, reply_markup=menu)
    else:
        await callback_query.message.edit_text("‚ùå –ù–µ–∏–∑–≤–µ—Å—Ç–Ω–∞—è –Ω–∞—Å—Ç—Ä–æ–π–∫–∞.")

#  –û–±—Ä–∞–±–æ—Ç–∫–∞ –≤—ã–±–æ—Ä–∞ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤
@dp.callback_query_handler(lambda c: c.data.startswith("set_"))
async def update_setting(callback_query: types.CallbackQuery):
    await callback_query.answer()
    user_id = callback_query.from_user.id
    data = callback_query.data

    key_map = {
        "size": ["set_size_", "$1"],
        "quality": ["set_quality_", "$2"],
        "background": ["set_background_", "$3"],
    }

    for key, [prefix, path] in key_map.items():
        if data.startswith(prefix):
            value = data.replace(prefix, "").replace("_", " ")
            value = value.replace("png", "").strip()

            # –ï—Å–ª–∏ –ø—Ä–æ–∑—Ä–∞—á–Ω–æ—Å—Ç—å, —Ç–æ –∑–Ω–∞—á–µ–Ω–∏–µ transparent
            if key == "background" and value == "transparent":
                value = "transparent"
            elif key == "background":
                value = "opaque"

            # –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ–º –∑–Ω–∞—á–µ–Ω–∏–µ –≤ JSON —Å—Ç—Ä–æ–∫—É
            json_value = f'"{value}"'

            await update_image_openai_settings(user_id, [key], json_value)

            await image_settings_handler(callback_query)  # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –æ–±–Ω–æ–≤–ª—ë–Ω–Ω—ã–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏
            break

@dp.callback_query_handler(lambda c: c.data == "back_to_settings")
async def back_to_settings(callback_query: types.CallbackQuery):
    await callback_query.answer()
    await image_settings_handler(callback_query)