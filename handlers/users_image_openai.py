from io import BytesIO

from aiogram import types
from aiogram.dispatcher import FSMContext
from aiogram.dispatcher.filters.state import State, StatesGroup
from openai import OpenAI
import base64
import tempfile
import os
import json
from config import OPENAPI_TOKEN
from create_bot import dp, bot
from handlers.users import not_enough_balance
from keyboards.user import image_openai_menu
from utils import db
from utils.ai import get_translate
from typing import Literal
import logging


logger = logging.getLogger(__name__)

logging.basicConfig(
    level=logging.INFO,
    format='%(filename)s:%(lineno)d #%(levelname)-8s '
           '[%(asctime)s] - %(name)s - %(message)s')


# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∫–ª–∏–µ–Ω—Ç–∞ OpenAI
client = OpenAI(api_key=OPENAPI_TOKEN)

# FSM –¥–ª—è —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è —Å–æ—Å—Ç–æ—è–Ω–∏–µ–º –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π
class ImageGenerationStates(StatesGroup):
    WAITING_FOR_PROMPT = State()
    WAITING_FOR_IMAGES = State()
    WAITING_FOR_MASK = State()

# –î–æ–ø—É—Å—Ç–∏–º—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è
ALLOWED_SIZES = {
    "auto",
    "1024x1024", "1536x1024", "1024x1536",
    "256x256", "512x512",
    "1792x1024", "1024x1792"
}

ALLOWED_QUALITY = {
    "standard", "hd", "low", "medium", "high", "auto"
}

ALLOWED_BACKGROUND = {
    "transparent", "opaque", "auto"
}

# –¢–∏–ø—ã –¥–ª—è —Å—Ç—Ä–æ–≥–æ–π —Ç–∏–ø–∏–∑–∞—Ü–∏–∏
SizeType = Literal[
    "auto",
    "1024x1024", "1536x1024", "1024x1536",
    "256x256", "512x512",
    "1792x1024", "1024x1792"
]
QualityType = Literal["standard", "hd", "low", "medium", "high", "auto"]
BackgroundType = Literal["transparent", "opaque", "auto"]


# –°–ª–æ–≤–∞—Ä—å —Å—Ç–æ–∏–º–æ—Å—Ç–∏ —Ç–æ–∫–µ–Ω–æ–≤ –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç —Ä–∞–∑–º–µ—Ä–∞ –∏ –∫–∞—á–µ—Å—Ç–≤–∞
def calculate_token_cost(size, quality):
    cost_map = {
        ("1024x1024", "low"): 272,
        ("1024x1024", "medium"): 1056,
        ("1024x1024", "high"): 4160,

        ("1536x1024", "low"): 400,
        ("1536x1024", "medium"): 1568,
        ("1536x1024", "high"): 6208,

        ("1024x1536", "low"): 408,
        ("1024x1536", "medium"): 1584,
        ("1024x1536", "high"): 6240,
    }
    return cost_map.get((size, quality), 1056)


# –ì–ª–∞–≤–Ω–æ–µ –º–µ–Ω—é –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –æ—Ç OpenAI
@dp.message_handler(state="*", text="üé®Image OpenAI‚úÖ")
@dp.message_handler(state="*", text="üé®Image OpenAI")
@dp.message_handler(state="*", commands="image_openai")
async def image_openai_menu_handler(message: types.Message, state: FSMContext):
    if state:
        await state.finish()  # –ó–∞–≤–µ—Ä—à–∞–µ–º —Ç–µ–∫—É—â–µ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ
    await db.change_default_ai(message.from_user.id, "image_openai")  # –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º ChatGPT –∫–∞–∫ –æ—Å–Ω–æ–≤–Ω–æ–π AI
    user_id = message.from_user.id
    logger.info(f"–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å {user_id} –≤—ã–∑–≤–∞–ª –ì–ª–∞–≤–Ω–æ–µ –º–µ–Ω—é –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –æ—Ç OpenAI")


# –ù–∞—á–∞–ª–æ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –ø–æ —Ç–µ–∫—Å—Ç—É
@dp.callback_query_handler(lambda c: c.data == "generate_image_prompt")
async def start_generate_image(callback_query: types.CallbackQuery, state: FSMContext):
    await callback_query.answer()
    user_id = callback_query.from_user.id

    if not await db.has_image_openai_balance(user_id):
        logger.info(f'–£ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è {user_id} –Ω–µ—Ç –≥–µ–Ω–µ—Ä–∞—Ü–∏–π –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –æ—Ç OpenAI, –ø–µ—Ä–µ–¥–∞–µ–º –º–µ–Ω—é —Å –ø–æ–∫—É–ø–∫–æ–π –≥–µ–Ω–µ—Ä–∞—Ü–∏–π')
        await not_enough_balance(callback_query.bot, user_id, "image_openai")
        return

    await callback_query.message.edit_text("""<b>‚úçÔ∏è –í–≤–µ–¥–∏—Ç–µ —Ç–µ–∫—Å—Ç–æ–≤–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è.</b>
<i>–ù–∞–ø—Ä–∏–º–µ—Ä:</i> <code>–£—é—Ç–Ω—ã–π –¥–æ–º–∏–∫ –Ω–∞ –∫—Ä–∞—é –ø—Ä–æ–ø–∞—Å—Ç–∏, –æ–∫—Ä—É–∂—ë–Ω–Ω—ã–π —Ü–≤–µ—Ç—É—â–∏–º–∏ —Å–∞–¥–∞–º–∏ –∏ –æ–∑—ë—Ä–∞–º–∏ —Å –æ—Ç—Ä–∞–∂–∞—é—â–∏–º—Å—è –Ω–µ–±–æ–º</code>

<u><a href="https://telegra.ph/Kak-polzovatsya-MidJourney-podrobnaya-instrukciya-10-16">–ü–æ–¥—Ä–æ–±–Ω–∞—è –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏—è.</a></u>""",
                         disable_web_page_preview=True)

    await ImageGenerationStates.WAITING_FOR_PROMPT.set()


def parse_image_settings(settings_str: str) -> dict[str, str]:
    try:
        data = json.loads(settings_str)
    except json.JSONDecodeError:
        data = {}

    size = data.get("size", "1024x1024")
    if size not in ALLOWED_SIZES:
        size = "1024x1024"

    quality = data.get("quality", "medium")
    if quality not in ALLOWED_QUALITY:
        quality = "medium"

    background = data.get("background", "opaque")
    if background not in ALLOWED_BACKGROUND:
        background = "opaque"

    return {
        "size": size,
        "quality": quality,
        "background": background
    }


# –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –Ω–∞ –æ—Å–Ω–æ–≤–µ –ø—Ä–æ–º–ø—Ç–∞
@dp.message_handler(state=ImageGenerationStates.WAITING_FOR_PROMPT)
async def generate_image_from_prompt(message: types.Message, state: FSMContext):
    user_id = message.from_user.id
    prompt = message.text.strip()
    logger.info(f'–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è OpenAI, –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å {user_id}, prompt: {prompt} ')
    prompt = await get_translate(prompt)  # –ü–µ—Ä–µ–≤–æ–¥–∏–º –∑–∞–ø—Ä–æ—Å –Ω–∞ –∞–Ω–≥–ª–∏–π—Å–∫–∏–π

    if not prompt:
        await message.answer("‚ùå –û–ø–∏—Å–∞–Ω–∏–µ –Ω–µ –º–æ–∂–µ—Ç –±—ã—Ç—å –ø—É—Å—Ç—ã–º. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ —Å–Ω–æ–≤–∞.")
        return

    user = await db.get_user(user_id)

    settings = parse_image_settings(user["image_openai_settings"])
    size: SizeType = settings["size"]
    quality: QualityType = settings["quality"]
    background: BackgroundType = settings["background"]

    try:
        # result = client.images.generate(
        #     model="gpt-image-1",
        #     prompt=prompt,
        #     size=size,
        #     quality=quality,
        #     background=background
        # )
        #
        # image_base64 = result.data[0].b64_json
        # image_bytes = base64.b64decode(image_base64)
        #
        # # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—é
        # await bot.send_photo(chat_id=user_id, photo=types.InputFile(BytesIO(image_bytes), filename="generated.png"))
        # –ü—É—Ç—å –∫ —Ñ–∞–π–ª—É
        file_path = "photos/generated.png"
        # –û—Ç–ø—Ä–∞–≤–∫–∞ —Ñ–æ—Ç–æ –ø–æ –ø—É—Ç–∏
        await bot.send_photo(chat_id=user_id, photo=types.InputFile(file_path))

        # –£–º–µ–Ω—å—à–∞–µ–º –±–∞–ª–∞–Ω—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
        await db.decrease_image_openai_balance(user_id)

        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –¥–µ–π—Å—Ç–≤–∏–µ –≤ –±–∞–∑–µ –¥–∞–Ω–Ω—ã—Ö
        await db.add_action(user_id, "image_openai", "generate")
        # –õ–æ–≥–∏—Ä—É–µ–º –¥–µ–π—Å—Ç–≤–∏–µ
        logger.info(f"–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å {user_id} —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–ª –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ: {prompt[:50]}...")

    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –¥–ª—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è {user_id}: {e}", exc_info=True)
        await message.answer("–ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –ø—Ä–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –ø–æ–∑–∂–µ.")

    finally:
        await state.finish()


# –ù–∞—á–∞–ª–æ —Ä–µ–¥–∞–∫—Ç–∏—Ä–æ–≤–∞–Ω–∏—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
@dp.callback_query_handler(lambda c: c.data == "edit_image")
async def start_edit_image(callback_query: types.CallbackQuery, state: FSMContext):
    await callback_query.answer()
    user_id = callback_query.from_user.id

    if not await db.has_image_openai_balance(user_id):
        await not_enough_balance(callback_query.bot, user_id, "image_openai")
        return

    await callback_query.message.edit_text("""<b>üì∏ –ü—Ä–∏—à–ª–∏—Ç–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è, –∫–æ—Ç–æ—Ä—ã–µ —Ö–æ—Ç–∏—Ç–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –∫–∞–∫ –æ—Å–Ω–æ–≤—É –¥–ª—è —Ä–µ–¥–∞–∫—Ç–∏—Ä–æ–≤–∞–Ω–∏—è.</b>"
<i>–í—ã –º–æ–∂–µ—Ç–µ:
- –†–µ–¥–∞–∫—Ç–∏—Ä–æ–≤–∞—Ç—å —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
- –°–æ–∑–¥–∞–≤–∞–π—Ç–µ –Ω–æ–≤—ã–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è, –∏—Å–ø–æ–ª—å–∑—É—è –¥—Ä—É–≥–∏–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –≤ –∫–∞—á–µ—Å—Ç–≤–µ —Å–ø—Ä–∞–≤–æ—á–Ω—ã—Ö –º–∞—Ç–µ—Ä–∏–∞–ª–æ–≤.</i>

<u><a href="https://telegra.ph/Kak-polzovatsya-MidJourney-podrobnaya-instrukciya-10-16">–ü–æ–¥—Ä–æ–±–Ω–∞—è –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏—è.</a></u>""",
                                           disable_web_page_preview=True)

    await ImageGenerationStates.WAITING_FOR_IMAGES.set()


# –û–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π
@dp.message_handler(content_types=['photo'], state=ImageGenerationStates.WAITING_FOR_IMAGES)
async def handle_images_upload(message: types.Message, state: FSMContext):
    user_id = message.from_user.id
    data = await state.get_data()
    images_paths = data.get("images_paths", [])
    temp_dirs = data.get("temp_dirs", [])

    if len(images_paths) >= 10:
        await message.answer("‚ö†Ô∏è –í—ã –Ω–µ –º–æ–∂–µ—Ç–µ –∑–∞–≥—Ä—É–∑–∏—Ç—å –±–æ–ª—å—à–µ 10 –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π.")
        return

    photo = message.photo[-1]
    file = await bot.get_file(photo.file_id)
    downloaded_file = await bot.download_file(file.file_path)

    temp_dir = tempfile.TemporaryDirectory()
    image_path = os.path.join(temp_dir.name, f"{user_id}_{len(images_paths)}.png")

    with open(image_path, 'wb') as new_file:
        new_file.write(downloaded_file.getvalue())

    images_paths.append(image_path)
    temp_dirs.append(temp_dir)

    await state.update_data(images_paths=images_paths, temp_dirs=temp_dirs)

    if len(images_paths) < 10:
        await message.answer(f"üñºÔ∏è –ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(images_paths)} –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ(–π). –ü—Ä–æ–¥–æ–ª–∂–∞–π—Ç–µ –æ—Ç–ø—Ä–∞–≤–ª—è—Ç—å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è (–¥–æ 10 —à—Ç—É–∫), –∑–∞—Ç–µ–º –Ω–∞–ø–∏—à–∏—Ç–µ –æ–ø–∏—Å–∞–Ω–∏–µ.")
    else:
        await message.answer("‚úÖ –ú–∞–∫—Å–∏–º—É–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –∑–∞–≥—Ä—É–∂–µ–Ω–æ. –¢–µ–ø–µ—Ä—å –≤–≤–µ–¥–∏—Ç–µ —Ç–µ–∫—Å—Ç–æ–≤–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ –¥–ª—è –æ–±—ä–µ–¥–∏–Ω–µ–Ω–∏—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π.")
        await ImageGenerationStates.WAITING_FOR_PROMPT.set()


# @dp.message_handler(content_types=['photo'], state=ImageGenerationStates.WAITING_FOR_IMAGES)
# async def handle_images_upload(message: types.Message, state: FSMContext):
#     user_id = message.from_user.id
#     photo = message.photo[-1]  # –°–∞–º–æ–µ –±–æ–ª—å—à–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
#     file = await bot.get_file(photo.file_id)
#     downloaded_file = await bot.download_file(file.file_path)
#
#     temp_dir = tempfile.TemporaryDirectory()
#     image_path = os.path.join(temp_dir.name, f"{user_id}.png")
#
#     with open(image_path, 'wb') as new_file:
#         new_file.write(downloaded_file.getvalue())
#
#     await state.update_data(images_paths=[image_path], temp_dir=temp_dir)
#     await message.answer("""<b>‚úçÔ∏è–¢–µ–ø–µ—Ä—å –≤–≤–µ–¥–∏—Ç–µ —Ç–µ–∫—Å—Ç–æ–≤–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ, –∫–∞–∫ –≤—ã —Ö–æ—Ç–∏—Ç–µ –∏–∑–º–µ–Ω–∏—Ç—å —ç—Ç–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ.
# –ï—Å–ª–∏ –Ω–µ—Å–∫–æ–ª—å–∫–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π, —Ç–æ –º–æ–∂–Ω–æ —Å–æ–∑–¥–∞—Ç—å –Ω–æ–≤–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –∏–∑ –Ω–∏—Ö.</b>
#
# <i>–ù–∞–ø—Ä–∏–º–µ—Ä:</i> <code>–°–æ–∑–¥–∞–π –ø–æ–¥–∞—Ä–æ—á–Ω—É—é –∫–æ—Ä–∑–∏–Ω—É, —Å–æ–¥–µ—Ä–∂–∞—â—É—é –ø—Ä–µ–¥–º–µ—Ç—ã —Å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π</code>
#
# <u><a href="https://telegra.ph/Kak-polzovatsya-MidJourney-podrobnaya-instrukciya-10-16">–ü–æ–¥—Ä–æ–±–Ω–∞—è –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏—è.</a></u>""",
#                                            disable_web_page_preview=True)
#
#     await ImageGenerationStates.WAITING_FOR_PROMPT.set()


# –û–±—Ä–∞–±–æ—Ç–∫–∞ –º–∞—Å–∫–∏ –¥–ª—è inpainting
@dp.callback_query_handler(lambda c: c.data == "use_mask_for_edit")
async def use_mask_for_edit(callback_query: types.CallbackQuery, state: FSMContext):
    await callback_query.answer()
    await callback_query.message.answer("üñºÔ∏è –ó–∞–≥—Ä—É–∑–∏—Ç–µ –º–∞—Å–∫—É. –ó–∞–∫—Ä–∞—à–µ–Ω–Ω—ã–µ –æ–±–ª–∞—Å—Ç–∏ –±—É–¥—É—Ç –∏–∑–º–µ–Ω–µ–Ω—ã.")
    await ImageGenerationStates.WAITING_FOR_MASK.set()


# –û–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –º–∞—Å–∫–∏
@dp.message_handler(content_types=['photo'], state=ImageGenerationStates.WAITING_FOR_MASK)
async def handle_mask_upload(message: types.Message, state: FSMContext):
    user_id = message.from_user.id
    photo = message.photo[-1]
    file = await bot.get_file(photo.file_id)
    downloaded_file = await bot.download_file(file.file_path)

    temp_dir = tempfile.TemporaryDirectory()
    mask_path = os.path.join(temp_dir.name, f"{user_id}_mask.png")

    with open(mask_path, 'wb') as new_file:
        new_file.write(downloaded_file.getvalue())

    await state.update_data(mask_path=mask_path, temp_dir=temp_dir)
    await message.answer("–¢–µ–ø–µ—Ä—å –æ—Ç–ø—Ä–∞–≤—å—Ç–µ –æ–ø–∏—Å–∞–Ω–∏–µ —Ç–æ–≥–æ, —á—Ç–æ –≤—ã —Ö–æ—Ç–∏—Ç–µ –∏–∑–º–µ–Ω–∏—Ç—å.")
    await ImageGenerationStates.WAITING_FOR_PROMPT.set()


# –û–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–ø—Ä–æ—Å–∞ –Ω–∞ —Ä–µ–¥–∞–∫—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ
@dp.message_handler(state=ImageGenerationStates.WAITING_FOR_PROMPT)
async def handle_edit_prompt(message: types.Message, state: FSMContext):
    prompt = message.text.strip()
    user_id = message.from_user.id

    data = await state.get_data()
    images_paths = data.get('images_paths', [])
    mask_path = data.get('mask_path')

    if not images_paths:
        await message.answer("‚ùå –ù–µ –Ω–∞–π–¥–µ–Ω–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –¥–ª—è —Ä–µ–¥–∞–∫—Ç–∏—Ä–æ–≤–∞–Ω–∏—è.")
        return

    user = await db.get_user(user_id)
    settings = user["image_openai_settings"]
    size = settings.get("size", "1024x1024")
    quality = settings.get("quality", "medium")
    background = settings.get("background", "opaque")

    try:
        if mask_path:
            result = client.images.edit(
                model="gpt-image-1",
                image=open(images_paths[0], "rb"),
                mask=open(mask_path, "rb"),
                prompt=prompt,
                size=size,
                quality=quality,
                background=background
            )
        else:
            result = client.images.edit(
                model="gpt-image-1",
                image=[open(p, "rb") for p in images_paths],
                prompt=prompt,
                size=size,
                quality=quality,
                background=background
            )

        image_base64 = result.data[0].b64_json
        image_bytes = base64.b64decode(image_base64)

        await bot.send_photo(chat_id=user_id, photo=types.InputFile(BytesIO(image_bytes), filename="edited.png"))
        await db.decrease_image_openai_balance(user_id)
        await db.add_action(user_id, "image_openai", "edit")

        logger.info(f"–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å {user_id} –æ—Ç—Ä–µ–¥–∞–∫—Ç–∏—Ä–æ–≤–∞–ª –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ: {prompt[:50]}...")

    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Ä–µ–¥–∞–∫—Ç–∏—Ä–æ–≤–∞–Ω–∏–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –¥–ª—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è {user_id}: {e}", exc_info=True)
        await message.answer("–ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –ø—Ä–∏ —Ä–µ–¥–∞–∫—Ç–∏—Ä–æ–≤–∞–Ω–∏–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –ø–æ–∑–∂–µ.")

    finally:
        await state.finish()
        data.get('temp_dir', None) and data['temp_dir'].cleanup()